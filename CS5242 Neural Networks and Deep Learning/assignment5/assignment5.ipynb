{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81b4243b-ca14-43d3-b2bd-591edd096e0a",
   "metadata": {},
   "source": [
    "# CS 5242 Homework 5\n",
    "\n",
    "In this assignment, we are going to dive into autoencoders (AE) and variational autoencoders (VAE). AEs are powerful discriminative models while VAEs are widely used in generation tasks. \n",
    "\n",
    "### **Submission**\n",
    "\n",
    "ASSIGNMENT DEADLINE ‚è∞ : **23:59 10 Apr 2024**\n",
    "\n",
    "Rename this file as \"{StuID}_{Name}_assignment-5.ipynb\" (e.g., \"A0100000J_Wang-Wenjie_assignment-5.ipynb\"), and submit it to Canvas. Make sure all outputs are saved in this file as we will not run any code for you. Do **not** submit any other files, especially dataset files.\n",
    "\n",
    "\n",
    "### **Contact**\n",
    "\n",
    "Feel free to reach me if you have any question about this homework.\n",
    "\n",
    "Slack: Xiangyu Peng\n",
    "\n",
    "Email: xiangyupeng@comp.nus.edu.sg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccbf757-1117-4f9e-97d5-05b1affcbd38",
   "metadata": {},
   "source": [
    "## Task 1: Training an autoencoder (AE)\n",
    "In task 1, the goal is to train an autoencoder (AE), which consists of an encoder and a decoder. AE is capable of learning meaningful representations in the latent space, which could be used for tasks like classification. Let's see how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96934b0-1651-4715-aa84-83690aa97807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 128\n",
    "\n",
    "# MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Autoencoder Model\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        x = x.flatten(1)\n",
    "        x_enc = self.encoder(x)\n",
    "        x_dec = self.decoder(x_enc)\n",
    "        x_recon = x_dec.reshape(B, C, H, W)\n",
    "        return x_recon\n",
    "\n",
    "# Instantiate the model\n",
    "input_dim = 28 * 28\n",
    "hidden_dim = 32\n",
    "model = Autoencoder(input_dim, hidden_dim).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bf1f4a-c2dd-4fea-98f9-5de2a74294ea",
   "metadata": {},
   "source": [
    "We have prepared the dataset and the AE model for you. Your task is to implement the training code and meet the following requirements:\n",
    "- use mean squared error (MSE) as the loss function\n",
    "- use a proper optimizer and a proper learning rate\n",
    "- train the model for 10 epochs\n",
    "- plot the training loss curve (at least 20 points in the curve, since we train 20 epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d2f132-e10d-4211-8259-cc6f6847a722",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "# TODO: train the AE model (2 points)\n",
    "##############################################\n",
    "# Your code starts here\n",
    "##############################################\n",
    "\n",
    "    \n",
    "##############################################\n",
    "# Your code ends here\n",
    "##############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2363660-e891-406a-860e-ffd18a965edd",
   "metadata": {},
   "source": [
    "Verify your AE is well trained by visualizing reconstructed images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e11bb8-5455-48b1-b8e1-461adb31f0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing reconstructed images\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "sample_list = []\n",
    "for idx_class in range(10):\n",
    "    indices_i = (test_dataset.targets == idx_class).nonzero().view(-1)\n",
    "    idx_sample = indices_i[0]\n",
    "    sample = test_dataset[idx_sample]\n",
    "    sample_list.append(sample[0])\n",
    "x_orig = torch.stack(sample_list).to(device)\n",
    "\n",
    "# Inference\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    x_recon = model(x_orig)\n",
    "\n",
    "# Plot the input and reconstructed images\n",
    "imgs_orig = make_grid(x_orig, nrow=10, padding=0, normalize=True)\n",
    "imgs_recon = make_grid(x_recon, nrow=10, padding=0, normalize=True)\n",
    "\n",
    "print('Input Images:')\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.imshow(imgs_orig.permute(1, 2, 0).cpu().numpy())\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print('Reconstructed Images:')\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.imshow(imgs_recon.permute(1, 2, 0).cpu().numpy())\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d2c478-7a91-4fa9-ba24-07547fe22854",
   "metadata": {},
   "source": [
    "Now we have trained an AE. Let's see how it can be used for classification. You are required to plot a [t-SNE](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding) map of the latent representations output by the encoder. Implement the code below and follow these requirements:\n",
    "- plot a 2D t-SNE map\n",
    "- plot 20 samples for each class in the **test** set (i.e., 20 points for each digit from 0 to 9)\n",
    "- use different colors for each digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cd0717-0a9e-41bb-a9f3-0d6e4b788d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# TODO: Plot t-SNE map (1.5 point)\n",
    "##############################################\n",
    "# Your code starts here\n",
    "##############################################\n",
    "\n",
    "\n",
    "##############################################\n",
    "# Your code ends here\n",
    "##############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b316a6-dc39-4d1f-89b0-b41536e1bd30",
   "metadata": {},
   "source": [
    "Can you see the separation/classification of different digits?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84593ae8-a343-4d62-a2ed-00be462d5163",
   "metadata": {},
   "source": [
    "## Task 2: Training a variational autoencoder (VAE)\n",
    "We have trained an AE in task 1, which is demonstrated to be useful for classification. However, only the encoder of AE is used. The decoder part, which is capable of reconstruction, is wasted. Can we use the decoder for generating images?\n",
    "\n",
    "The answer is yes. But some modifications are needed to achieve this goal. The general idea is to impose a prior distribution $p(z)$ on the latent space and constrain the learned distribution $q(z|x)$ to be close to $p(z)$, so that we can gain control over the learned latent distribution. Then, we can generate images using the decoder by sampling data points from the latent distribution. Actually, this is all about what a variational autoencoder (VAE) could do.\n",
    "\n",
    "Typically, people use the standard normal distribution as the prior latent distribution (i.e., $p(z)= N(0, I)$), which has $ \\mu=0 $ and $ \\sigma=I $. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86beb84-4439-4d09-921e-e7e76dad8355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 128\n",
    "\n",
    "# MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# VAE Model\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.mu = nn.Linear(256, latent_dim)\n",
    "        self.log_var = nn.Linear(256, latent_dim)\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        x = x.flatten(1)\n",
    "\n",
    "        h = self.encoder(x)\n",
    "\n",
    "        mu, log_var = self.mu(h), self.log_var(h)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "\n",
    "        x_dec = self.decoder(z)\n",
    "        x_recon = x_dec.reshape(B, C, H, W)\n",
    "\n",
    "        return x_recon, mu, log_var\n",
    "\n",
    "# Instantiate the model\n",
    "input_dim = 28 * 28\n",
    "latent_dim = 32\n",
    "model = VAE(input_dim, latent_dim).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c3ca7c-55b3-4730-b859-8611d020e209",
   "metadata": {},
   "source": [
    "Again, We have prepared the dataset and the VAE model for you. Your task is to implement the training code and meet the following requirements:\n",
    "- The loss function consists of 2 parts: 1) BinaryCrossEntropy (BCE) loss as the reconstruction loss; 2) KL divergence loss to minimize the distance between $q(z|x)$ and $p(z)$. Note that $p(z)= N(0, I)$\n",
    "- use a proper optimizer and a proper learning rate\n",
    "- train the model for 10 epochs\n",
    "- plot the training loss curve (at least 10 points in the curve, since we train 10 epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970ccc0e-7b9a-4bf3-a9d6-e5cfacd1c8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: train the VAE model (3 points)\n",
    "##############################################\n",
    "# Your code starts here\n",
    "##############################################\n",
    "\n",
    "    \n",
    "##############################################\n",
    "# Your code ends here\n",
    "##############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12d4931-2fed-4257-a673-0cbbca345059",
   "metadata": {},
   "source": [
    "Also, verify the sanity of the VAE model by visualizing reconstructed images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c98f01e-8242-416a-b653-e7f10b577f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing reconstructed images\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "sample_list = []\n",
    "for idx_class in range(10):\n",
    "    indices_i = (test_dataset.targets == idx_class).nonzero().view(-1)\n",
    "    idx_sample = indices_i[0]\n",
    "    sample = test_dataset[idx_sample]\n",
    "    sample_list.append(sample[0])\n",
    "x_orig = torch.stack(sample_list).to(device)\n",
    "\n",
    "# Inference\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    x_recon, mu, log_var = model(x_orig)\n",
    "\n",
    "# Plot the input and reconstructed images\n",
    "imgs_orig = make_grid(x_orig, nrow=10, padding=0, normalize=True)\n",
    "imgs_recon = make_grid(x_recon, nrow=10, padding=0, normalize=True)\n",
    "\n",
    "print('Input Images:')\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.imshow(imgs_orig.permute(1, 2, 0).cpu().numpy())\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print('Reconstructed Images:')\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.imshow(imgs_recon.permute(1, 2, 0).cpu().numpy())\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66d1274-e498-4484-859c-4de01793cb34",
   "metadata": {},
   "source": [
    "Now we have trained a VAE. Let's first check its latent distribution like we do for AE. You are required to plot a [t-SNE](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding) map of the latent representations output by the VAE encoder. Implement the code below and follow these requirements:\n",
    "- plot a 2D t-SNE map\n",
    "- plot 20 samples for each class in the **test** set (i.e., 20 points for each digit from 0 to 9)\n",
    "- use different colors for each digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c06f0b8-b2ac-4493-bf63-ded5208a4419",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# TODO: Plot t-SNE map (1.5 point)\n",
    "##############################################\n",
    "# Your code starts here\n",
    "##############################################\n",
    "\n",
    "\n",
    "##############################################\n",
    "# Your code ends here\n",
    "##############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d142245a-8c7a-4e53-921b-35c2dddaa853",
   "metadata": {},
   "source": [
    "Finally, we are able to generate images using the decoder of the VAE by sampling data points from $p(z)$. Implement the code below and meet these requirements:\n",
    "- sample 10 data points from $p(z)$\n",
    "- show them 5 images in a row, 2 rows in total\n",
    "- at least one image should be recognized as a digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7915d22e-7813-477b-86c5-1fd0697841a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: generate digits using the decoder of VAE (1 point)\n",
    "##############################################\n",
    "# Your code starts here\n",
    "##############################################\n",
    "\n",
    "\n",
    "##############################################\n",
    "# Your code ends here\n",
    "##############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3799fdb6-cc62-4888-97ad-1d14b0439e03",
   "metadata": {},
   "source": [
    "Open question: We can now generate digits by sampling from the latent distribution. But we cannot control which digit to generate. Do you have any idea about how can we manage to generate any digit we want?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a7560e-efbc-423e-abb9-d6023ba9e7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Your answer here (1 point)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
