{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXMX8yuAyl55"
      },
      "source": [
        "# Welcome to CS 5242 **Assignment 2**\n",
        "\n",
        "ASSIGNMENT DEADLINE ⏰ : ** 3 March 2024** \n",
        "\n",
        "In this assignment, we have three parts:\n",
        "1. Implement some operations in CNNs from scratch *(2 Points)*\n",
        "2. Implement a simple CNN and train on MNIST using PyTorch  *(4 Points)*\n",
        "3. Implement a VGG network with PyTorch *(4 Points)*\n",
        "\n",
        "Colab is a hosted Jupyter notebook service that requires no setup to use, while providing access free of charge to computing resources including GPUs. In this semester, we will use Colab to run our experiments.\n",
        "1. Login Google Colab https://colab.research.google.com/\n",
        "2. In this assignment, We **need GPU** to training the CNN model. You may need to **choose GPU in Runtime -> Change runtime type -> Hardware accerator**\n",
        "![Alt text](image.png)\n",
        "\n",
        "\n",
        "### **Grades Policy**\n",
        "\n",
        "We have 10 points for this homework. 15% off per day late, 0 scores if you submit it 7 days after the deadline.\n",
        "\n",
        "### **Cautions**\n",
        "\n",
        "**DO NOT** copy the code from the internet, e.g. GitHub.\n",
        "---\n",
        "\n",
        "**DO NOT** use any LLMs to write the code, e.g. ChatGPT.\n",
        "---\n",
        "\n",
        "### **Contact**\n",
        "\n",
        "Please feel free to contact us if you have any question about this homework or need any further information.\n",
        "\n",
        "Slack: Wangbo Zhao\n",
        "\n",
        "\n",
        "> If you have not join the slack group, you can click [here](https://join.slack.com/t/cs5242-2024spring/shared_invite/zt-2cw3jgqab-wFhoaIVa4RIX4fCZ_k~vjQ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLeZHcOVBp4U"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Start by running the cell below to set up all required software."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIgu_q2HBg-E",
        "outputId": "1cf793d6-017c-480d-ccf7-bdafc8c4a4b0"
      },
      "outputs": [],
      "source": [
        "!pip install numpy matplotlib \n",
        "!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtXcchT5H2PH"
      },
      "source": [
        "Import the neccesary library and fix seed for Python, NumPy and PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2Yodsn4H6CB",
        "outputId": "abeeb6fb-59b7-4318-eb50-5b54a949f6de"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTpFBLKSkKI0"
      },
      "source": [
        "Now let's setup the GPU environment. The colab provides a free GPU to use. Do as follows:\n",
        "\n",
        "- Runtime -> Change Runtime Type -> select `GPU` in Hardware accelerator\n",
        "- Click `connect` on the top-right\n",
        "\n",
        "After connecting to one GPU, you can check its status using `nvidia-smi` command."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ES8KOxziiYky",
        "outputId": "4e46e3bd-e922-4bc1-c7ca-bc6b4eae6d4b"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi\n",
        "\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yrZD7DDExF4"
      },
      "source": [
        "Everything is ready, you can move on and ***Good Luck !*** 😃"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tm1f362vdRgF"
      },
      "source": [
        "## Implement some operations in CNNs from scratch\n",
        "\n",
        "In this section, you need to implement some operations commonly used in CNNs, including convolution and pooling. \n",
        "\n",
        "You need to compare the computational results of your implemented version with those of Pytorch, expecting that the error between the correct implementation and pytorch will be very small.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NV3DXc2jgeg7"
      },
      "source": [
        "### Step 1\n",
        "Given a 32x32 pixels, 3 channels input, get a torch tensor with torch.randn()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UxGJxTegq9O"
      },
      "outputs": [],
      "source": [
        "batch_size = 2\n",
        "c = 3\n",
        "h = 32\n",
        "w = 32\n",
        "x = torch.randn(batch_size, c, h, w)\n",
        "print(x)\n",
        "print(x.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxnlbBnFw9wB"
      },
      "source": [
        "### Step 2\n",
        "We first implement these operations with Pytorch so that we can compare the computational results of our implemented version with those of original pytorch.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OLQGhRbJgpIZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 1. Build a max pooling layer torch_max_pool with Pytorch. The kernel size of the pooling is 2, the stride is 2, and there is not any padding.\n",
        "torch_max_pool = nn.MaxPool2d(kernel_size=2,\n",
        "                              stride=2,\n",
        "                              padding=0)\n",
        "\n",
        "# 2. Build a average pooling layer torch_avg_pool with Pytorch. The kernel size of the pooling is 2, the stride is 1. The padding shoulbd be set to 1.\n",
        "torch_avg_pool = nn.AvgPool2d(kernel_size=2,\n",
        "                              stride=1,\n",
        "                              padding=1)\n",
        "\n",
        "# 3.Build a 2D convolutional layer torch_conv with Pytorch. The kernel size of the convolution is 3. Stride is 1. The input channel and output channel should be set to 3 and 64, respectively. We use zero padding to keep the spatial size of the output feature.\n",
        "torch_conv = nn.Conv2d(in_channels=3,\n",
        "                       out_channels=64,\n",
        "                       kernel_size=3,\n",
        "                       stride=1,\n",
        "                       padding=1)\n",
        "\n",
        "# 2D batchnorm with channel=3\n",
        "torch_norm = nn.BatchNorm2d(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBzDAo2rgwmx"
      },
      "outputs": [],
      "source": [
        "torch_max_pool_out = torch_max_pool(x)\n",
        "print(torch_max_pool_out.shape)\n",
        "\n",
        "torch_avg_pool_out = torch_avg_pool(x)\n",
        "print(torch_avg_pool_out.shape)\n",
        "\n",
        "torch_conv_out = torch_conv(x)\n",
        "print(torch_conv_out.shape)\n",
        "\n",
        "torch_norm_out = torch_norm(x)\n",
        "print(torch_norm_out.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6YBRP6Qgylg"
      },
      "source": [
        "### Step 3\n",
        "\n",
        "Implement these operations from scratch. Output your tensors as \"my_xxx_out\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CsO5I40fgzWY"
      },
      "outputs": [],
      "source": [
        "def my_max_pool(x, kernel_size, stride, padding):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        x: torch tensor with size (N, C_in, H_in, W_in),\n",
        "        kernel_size: size of the window to take a max over, \n",
        "        stride: stride of the window,\n",
        "        padding: implicit zero padding to be added on both sides,\n",
        "        \n",
        "    Return:\n",
        "        y: torch tensor of size (N, C_out, H_out, W_out).\n",
        "    \"\"\"\n",
        "\n",
        "    y = None\n",
        "    # === Complete the code (0.5')\n",
        "\n",
        "    # === Complete the code\n",
        "    return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGbn6oQcg4pM"
      },
      "outputs": [],
      "source": [
        "def my_avg_pool(x, kernel_size, stride, padding):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        x: torch tensor with size (N, C_in, H_in, W_in),\n",
        "        kernel_size: size of the window, \n",
        "        stride: stride of the window,\n",
        "        padding: implicit zero padding to be added on both sides,\n",
        "        \n",
        "    Return:\n",
        "        y: torch tensor of size (N, C_out, H_out, W_out).\n",
        "    \"\"\"\n",
        "\n",
        "    y = None\n",
        "    # === Complete the code (0.5')\n",
        "\n",
        "    # === Complete the code\n",
        "    return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gsDytvKg5c1"
      },
      "outputs": [],
      "source": [
        "def my_conv(x, in_channels, out_channels, kernel_size, stride, padding, weight, bias):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        x: torch tensor with size (N, C_in, H_in, W_in),\n",
        "        in_channels: number of channels in the input image, it is C_in;\n",
        "        out_channels: number of channels produced by the convolution;\n",
        "        kernel_size: size of onvolving kernel, \n",
        "        stride: stride of the convolution,\n",
        "        padding: implicit zero padding to be added on both sides of each dimension,\n",
        "        \n",
        "    Return:\n",
        "        y: torch tensor of size (N, C_out, H_out, W_out)\n",
        "    \"\"\"\n",
        "\n",
        "    y = None\n",
        "    # === Complete the code (0.5')\n",
        "\n",
        "    # === Complete the code\n",
        "    return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8sX0oRyTg-m6"
      },
      "outputs": [],
      "source": [
        "def my_batchnorm(x, num_features, eps=1e-5):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        x: torch tensor with size (N, C, H, W),\n",
        "        num_features: number of features in the input tensor, it is C;\n",
        "        eps: a value added to the denominator for numerical stability. Default: 1e-5\n",
        "        \n",
        "    Return:\n",
        "        y: torch tensor of size (N, C, H, W)\n",
        "    \"\"\"\n",
        "\n",
        "    y = torch.empty_like(x)\n",
        "    # === Complete the code (0.5')\n",
        "\n",
        "    # === Complete the code\n",
        "    return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMnKzeVuhGxu"
      },
      "outputs": [],
      "source": [
        "my_max_pool_out = my_max_pool(x, kernel_size=, stride=, padding=)\n",
        "my_avg_pool_out = my_avg_pool(x, kernel_size=, stride=, padding=)\n",
        "my_conv_out = my_conv(x,\n",
        "                      in_channels=,\n",
        "                      out_channels=,\n",
        "                      kernel_size=,\n",
        "                      stride=,\n",
        "                      padding=)\n",
        "my_norm_out = my_batchnorm(x, num_features=, eps=1e-5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jO-EHT7wm7Dk"
      },
      "source": [
        "### Step 4\n",
        "\n",
        "Compare and show that \"torch_xxx_out\" and \"my_xxx_out\" are equal up to small numerical errors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXnNfKKJhOAi",
        "outputId": "e625a0d5-e049-4ec2-bd8b-d26c93f745db"
      },
      "outputs": [],
      "source": [
        "print(F.mse_loss(my_max_pool_out, torch_max_pool_out))\n",
        "print(F.mse_loss(my_avg_pool_out, torch_avg_pool_out))\n",
        "print(F.mse_loss(my_conv_out, torch_conv_out))\n",
        "print(F.mse_loss(my_norm_out, torch_norm_out))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHxuCzkmhP4l",
        "outputId": "dff10a9a-7295-4959-9380-05afed82a514"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJFZB_A7ddrC"
      },
      "source": [
        "## Implement a simple CNN and train it on MNIST using PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 1\n",
        "Create datasets. The MNIST data set is composed of handwritten digit images and digit labels from 0 to 9. It consists of 60,000 training samples and 10,000 test samples. Each sample is a 28 * 28 pixel grayscale handwritten digit image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch \n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "train_set = torchvision.datasets.FashionMNIST(\n",
        "    root = 'FashionMNIST/',\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        ")\n",
        "\n",
        "test_set = torchvision.datasets.FashionMNIST(\n",
        "    root = 'FashionMNIST/',\n",
        "    train = False,\n",
        "    download = True,\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        ")\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=100)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2\n",
        "Create the model.\n",
        "You can build a simple convolutional neural network to conduct the classification. You may refine the architecture based on the accuracy. You can also try different learning rates.\n",
        "**The test accuracy should achieve 85%.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Network,self).__init__()\n",
        "\n",
        "\n",
        "    def forward(self, input):\n",
        "\n",
        "        return t\n",
        "\n",
        "network = Network()\n",
        "if torch.cuda.is_available():\n",
        "    network = network.cuda()\n",
        "    \n",
        "\n",
        "optimizer = optim.Adam(network.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3\n",
        "\n",
        "Build the train and test loops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for epoch in range(10):\n",
        "    total_loss = 0\n",
        "    total_correct = 0\n",
        "    for batch in train_loader:  \n",
        "        images, labels = batch\n",
        "        if torch.cuda.is_available():\n",
        "            images = images.cuda()\n",
        "            labels = labels.cuda()\n",
        "\n",
        "        optimizer.zero_grad()  \n",
        "        preds = network(images)\n",
        "        loss = F.cross_entropy(preds, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        _,prelabels=torch.max(preds,dim=1)\n",
        "        total_correct += (prelabels==labels).sum().item()\n",
        "    accuracy = total_correct/len(train_set)\n",
        "    print(\"Epoch:%d  ,  Loss:%f  , Train Accuracy:%f \"%(epoch, total_loss, accuracy * 100))\n",
        "\n",
        "\n",
        "correct=0\n",
        "total=0\n",
        "network.eval()\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        imgs,labels=batch\n",
        "        if torch.cuda.is_available():\n",
        "            imgs = imgs.cuda()\n",
        "            labels = labels.cuda()\n",
        "        preds=network(imgs)\n",
        "        _,prelabels=torch.max(preds,dim=1)\n",
        "        #print(prelabels.size())\n",
        "        total=total+labels.size(0)\n",
        "        correct=correct+int((prelabels==labels).sum())\n",
        "    #print(total)\n",
        "    accuracy=correct / total\n",
        "    print(\"Test Accuracy: \", accuracy * 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Implement a VGG network with PyTorch \n",
        "VGG is a type of CNN (Convolutional Neural Network) that was considered to be one of the best computer vision models in 2015.\n",
        "https://arxiv.org/abs/1409.1556\n",
        "\n",
        "Here is the configuration of the network from its paper. Now, you need to implement **Config C** it with Pytorch.\n",
        "\n",
        "![Alt text](image-1.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class VGG(nn.Module):\n",
        "    def __init__(self, ) -> None:\n",
        "        super().__init__()\n",
        "    \n",
        "    def forward(image):\n",
        "        \n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, please calculate the number of parameters and FLOPs (Floating point operations) of **Config C**.\n",
        "You can only consider the FLOPs of the convolution and FC in **Config C**.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
